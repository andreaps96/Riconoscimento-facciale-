{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441f2502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import DPTFeatureExtractor, DPTForDepthEstimation\n",
    "\n",
    "from modello_antispoofing import (\n",
    "    AntiSpoofingModel,\n",
    "    RGBEncoder,\n",
    "    DepthEncoder\n",
    ")\n",
    "\n",
    "from insightface.app import FaceAnalysis\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import pytz\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "webhook_url = os.getenv(\"webhook_url\")\n",
    "\n",
    "#recupero datetime odierno\n",
    "def get_current_datetime(timezone='Europe/Rome',as_utc=False):\n",
    "    local_tz = pytz.timezone(timezone)\n",
    "    now_local = datetime.now(local_tz)\n",
    "\n",
    "    if as_utc:\n",
    "        now_utc = now_local.astimezone(pytz.utc)\n",
    "    else:\n",
    "        now_utc = now_local\n",
    "\n",
    "    return now_utc.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# chiamata webhook per innescare workflow n8n\n",
    "def create_presence(name,recognition_score=0.0):\n",
    "    try:\n",
    "        name,employee_id = name.split(\"-\") \n",
    "\n",
    "        datetime_utc = get_current_datetime(as_utc=True)\n",
    "\n",
    "        data = {\n",
    "            \"name\": name,\n",
    "            \"employee_id\": employee_id,\n",
    "            \"check_in\": datetime_utc,\n",
    "            \"recognition_score\": recognition_score\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            url=webhook_url,\n",
    "            json=data\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        print(f\"Presenza registrata: {name} alle {datetime_utc}\")\n",
    "        return response.json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Collegamento a n8n fallito: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e46f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FaceAnalysis(\n",
    "    name=\"buffalo_l\",\n",
    "    root='~/.insightface',\n",
    "    providers = ['OpenVINOExecutionProvider']\n",
    ")\n",
    "\n",
    "app.prepare(\n",
    "    ctx_id=0,\n",
    "    det_size=(640,640),\n",
    "    det_thresh=0.6\n",
    ")\n",
    "\n",
    "def build_db(train_dir,min_det_score=0.7):\n",
    "    db = {}\n",
    "    stats = {\n",
    "        \"total\": 0,\n",
    "        \"valid\": 0,\n",
    "        \"rejected\": 0\n",
    "    }\n",
    "\n",
    "    for person_dir in Path(train_dir).iterdir():\n",
    "        embeddings = []\n",
    "        person_name = person_dir.name\n",
    "\n",
    "        #calcolo embeddings per ogni persone presente in db\n",
    "        for img_path in tqdm(person_dir,desc=person_name):\n",
    "            stats[\"total\"] += 1\n",
    "\n",
    "            #caricamento immagine\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                stats[\"rejected\"] += 1\n",
    "                continue\n",
    "\n",
    "            #estrazione embeddings\n",
    "            faces = app.get(img)\n",
    "            if len(faces) == 0:\n",
    "                stats[\"rejected\"] += 1\n",
    "                print(f\"Immagine {img_path} scartata\")\n",
    "                continue\n",
    "\n",
    "            f = max(faces, key=lambda x: getattr(x, \"det_score\", 0.0))\n",
    "            det_score = getattr(f, \"det_score\", 0.0)\n",
    "\n",
    "            if det_score < min_det_score:\n",
    "                stats[\"rejected\"] += 1\n",
    "                print(f\"Immagine {img_path} scartata\")\n",
    "                continue\n",
    "\n",
    "            emb = f.embedding.astype(np.float32).ravel()\n",
    "            emb = emb / (np.linalg.norm(emb) + 1e-8)\n",
    "\n",
    "            if emb.ndim != 1 or emb.size != 128:\n",
    "                stats[\"rejected\"] += 1\n",
    "                print(f\"Immagine {img_path} scartata\")\n",
    "                continue\n",
    "\n",
    "            stats[\"valid\"] += 1\n",
    "            embeddings.append(emb)\n",
    "\n",
    "        if embeddings:\n",
    "            db[person_name] = np.stack(embeddings,axis=0)\n",
    "            print(f\"{person_name}: {len(embeddings)} immagini valide\")\n",
    "        else:\n",
    "            print(f\"Nessuna immagine valida per {person_name}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    print(f\"\\n Statistiche DB:\")\n",
    "    print(f\"   Totale immagini: {stats['total']}\")\n",
    "    print(f\"   Valide: {stats['valid']}\")\n",
    "    print(f\"   Scartate: {stats['rejected']}\")\n",
    "\n",
    "    return db\n",
    "\n",
    "print(\"Costruzione db\\n\")\n",
    "db = build_db(\"train\",min_det_score=0.7)\n",
    "\n",
    "with open(\"face_db.pkl\",\"wb\") as f:\n",
    "    pickle.dump(db,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ddacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(chekpoint_path,device):\n",
    "    print(\"Caricamento modello per stima della prodonfità\")\n",
    "    model = AntiSpoofingModel(RGBEncoder(),DepthEncoder())\n",
    "    try:\n",
    "        state_dict = torch.load(chekpoint_path,map_location=device)\n",
    "        model.load_state_dict(state_dict=state_dict,strict=False)\n",
    "        print(\"Modello anti-spoofing caricato.\")\n",
    "    except Exception as e:\n",
    "        return f\"Errore nel caricamento del modello di anti-spoofing: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a9d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_match_from_embedding(query_embedding,db,top_k=3):\n",
    "    best_name = \"Sconosciuto\"\n",
    "    best_score = -1.0\n",
    "\n",
    "    for name,emb in db.items():\n",
    "        arr = np.asarray(emb,dtype=np.float32)\n",
    "\n",
    "        if arr.ndim == 0:\n",
    "            print(f\"{name} ha un embedding vuoto\")\n",
    "            continue\n",
    "\n",
    "        elif arr.ndim ==1 :\n",
    "            if arr.shape[0] != 512:\n",
    "                print(f\"{name} ha un embedding di dimensione errata: {arr.shape[0]} anziché 512\")\n",
    "                continue\n",
    "            similarity = float(np.dot(query_embedding,arr))\n",
    "            \n",
    "        elif arr.ndim == 2:\n",
    "            if arr.shape[1] != 512:\n",
    "                print(f\"{name} ha un embedding di dimensione errata: {arr.shape[0]} anziché 512\")\n",
    "                continue\n",
    "            #prodotto matriciale --> (N,512) @ (512,1) = (Nresults,1)\n",
    "            similarities = arr @ query_embedding\n",
    "            k = np.min(top_k,len(similarities))\n",
    "            if k > 0:\n",
    "                top_indices = np.argpartition(similarities,-k)[-k:]\n",
    "                top_similarities = similarities[top_indices]\n",
    "                similarity = float(np.mean(top_similarities))\n",
    "            else:\n",
    "                similarity = -1.0\n",
    "        \n",
    "        if similarity > best_score:\n",
    "            best_score = similarity\n",
    "            best_name = name\n",
    "    \n",
    "    return best_name, best_score\n",
    "\n",
    "\n",
    "\n",
    "def recognize_face_from_frame(frame_bgr,db,threshold=0.8):\n",
    "    results = []\n",
    "\n",
    "    try:\n",
    "        faces = app.get(frame_bgr)\n",
    "    except Exception as e:\n",
    "        return f\"Errore nella detection del frame: {e}\"\n",
    "\n",
    "    for f in faces: \n",
    "        ##########################\n",
    "        det_score = getattr(f,\"det_score\",0.0)\n",
    "        if det_score < 0.7:\n",
    "            continue\n",
    "\n",
    "        emb = f.embeddings.astype(np.float32)\n",
    "        emb = emb / (np.linalg(emb) + 1e-8)\n",
    "\n",
    "        matched_name, score = db_match_from_embedding(emb,db)\n",
    "\n",
    "        if score < threshold:\n",
    "            name = \"Sconosciuto\"\n",
    "            label = f\"{name} (sim={score:.2f})\"\n",
    "        else:\n",
    "            name = matched_name\n",
    "            label = f\"{name} (sim={score}:.2f)\"\n",
    "        \n",
    "    bbox = tuple(map(int,f.bbox))\n",
    "    results.append((bbox,label,name,score))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb79e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "def estimate_depth_map(rgb_frame,feature_extractor,depth_model):\n",
    "    img_rgb = cv2.imread(rgb_frame,cv2.COLOR_BGR2RGB)\n",
    "    inputs = feature_extractor(\n",
    "        images=img_rgb,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = depth_model(**inputs)\n",
    "        predicted_depth = outputs.predicted_depth.squeeze().cpu().numpy()\n",
    "    \n",
    "    depth = predicted_depth - predicted_depth.min()\n",
    "    if depth.max > 0:\n",
    "        depth /= depth.max()\n",
    "        \n",
    "    return depth.astype(np.float32)\n",
    "    \n",
    "\n",
    "def preprocess_for_antispoofing(rgb_frame, depth_frame):\n",
    "    \"\"\"Preprocessa frame per anti-spoofing (ridimensiona a 224x224)\"\"\"\n",
    "    # RGB\n",
    "    rgb = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2RGB)\n",
    "    rgb = cv2.resize(rgb, (224, 224))\n",
    "    rgb = rgb.astype(np.float32) / 255.0\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    rgb = (rgb - mean) / std\n",
    "    rgb_tensor = torch.from_numpy(rgb.transpose(2, 0, 1)).unsqueeze(0)\n",
    "    \n",
    "    # Depth\n",
    "    depth = cv2.resize(depth_frame, (224, 224))\n",
    "    depth = np.clip(depth, 0, 1).astype(np.float32)\n",
    "    depth_tensor = torch.from_numpy(depth).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    return rgb_tensor.float(), depth_tensor.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978cd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Modello anti-spoofing\n",
    "antispoofing_model_path = os.getenv(\"checkpoint_path\")\n",
    "antispoofind_model = load_model(antispoofing_model_path)\n",
    "\n",
    "# 2. Modello calcolo mappe di profondità\n",
    "feature_extractor = DPTFeatureExtractor.from_pretrained(\"Intel/dpt-hybrid-midas\")\n",
    "depth_model = DPTForDepthEstimation.from_pretrained(\"Intel/dpt-hybrid-midas\").to(device)\n",
    "depth_model.eval()\n",
    "\n",
    "# 3. YOLO\n",
    "yolo_stride = 1\n",
    "yolo_weights = os.getenv(\"yolo_weights\")\n",
    "yolo = YOLO(yolo_weights)\n",
    "model_names = yolo.model.names\n",
    "phone_id = next((i,n) for i,n in model_names.items() if n.lower() == \"cell phone\")[0]\n",
    "\n",
    "# 4. Db embeddings\n",
    "with open(\"face_db.pkl\",\"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "    \n",
    "print(f\"Database caricato: {len(db)} persone\\n\")\n",
    "\n",
    "# Configurazione\n",
    "ANTISPOOFING_THRESHOLD = 0.7\n",
    "ANTISPOOFING_STRIDE = 1\n",
    "FACE_RECOGNITION_THRESHOLD = 0.8\n",
    "PHONE_CONF_THRESHOLD = 0.7\n",
    "\n",
    "phone_lock_timestamp = 0\n",
    "last_phone_dets = []\n",
    "last_antispoofing_result = (False, 0.0)\n",
    "should_webhook = False\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Non si accende la webcam\")\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "\n",
    "frame_idx = 0\n",
    "device_lock = False\n",
    "antispoofing_buffer = deque(maxlen=5)\n",
    "t_prev = time.time()\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" SISTEMA ATTIVO - MODALITÀ FRAME INTERO\")\n",
    "print(\"=\"*70)\n",
    "print(\"Comandi:\")\n",
    "print(\"  'q' = Esci\")\n",
    "print(\"  'r' =   Reset lock telefono (UNICO MODO PER SBLOCCARE)\")\n",
    "print(f\" Soglia AS: {ANTISPOOFING_THRESHOLD:.2f}\")\n",
    "print(f\" Soglia telefono: {PHONE_CONF_THRESHOLD:.2f}\")\n",
    "print(f\"  Lock: MANUALE ONLY (nessun timeout automatico)\")\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Errore nella lettura del frame dalla webcam\")\n",
    "        break\n",
    "    \n",
    "    frame = cv2.resize(frame,(0,0),fx=1.5,fy=1.5)\n",
    "    vis = frame.copy()\n",
    "    depth_colored = None\n",
    "\n",
    "    ### Yolo detection\n",
    "    if frame_idx % yolo_stride == 0 and not device_lock:\n",
    "        try:\n",
    "            res = yolo(frame,conf=PHONE_CONF_THRESHOLD,classes=[phone_id])\n",
    "            phone_dets_current = []\n",
    "            for b in res.boxes:\n",
    "                cls_id = int(b.cls[0])\n",
    "                if cls_id == phone_id:\n",
    "                    x1,y1,x2,y2 = map(int,b.xyxy[0].tolist())\n",
    "                    phone_dets_current.append((\n",
    "                        (x1,y1,x2,y2),\n",
    "                        float(b.conf[0])\n",
    "                    ))\n",
    "            if phone_dets_current:\n",
    "                last_phone_dets = phone_dets_current\n",
    "                \n",
    "                if not device_lock:\n",
    "                    device_lock = True\n",
    "                    phone_lock_timestamp = time.time()\n",
    "                    print(f\"Device lock attivo, telefono rilevato\")\n",
    "                    for (x1,y1,x2,y2),conf in phone_dets_current:\n",
    "                        print(f\"Bbox: ({x1},{y1})-({x2},{y2})) , conf={conf:.3f}\")\n",
    "                        \n",
    "        except Exception as e: \n",
    "            print(f\"Errore nella rivelazione di cellulari: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "    ### Anti-spoofing sul frame\n",
    "    frame_is_fake = False\n",
    "    prob_fake_smooth_global = 0.0\n",
    "\n",
    "    if not device_lock and (frame_idx % ANTISPOOFING_STRIDE == 0):\n",
    "        try:\n",
    "            depth_map_full = estimate_depth_map(frame,feature_extractor,depth_model)\n",
    "            rgb_t,depth_t = preprocess_for_antispoofing(frame,depth_map_full)\n",
    "            rgb_t, depth_t = rgb_t.to(device), depth_t.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                logits = antispoofind_model(rgb_t,depth_t)\n",
    "                probs = F.softmax(logits,dim=1)\n",
    "                prob_fake = probs[0,1].item()\n",
    "                antispoofing_buffer.append(prob_fake)\n",
    "            \n",
    "            prob_fake_smooth_global = np.mean(antispoofing_buffer)\n",
    "            frame_is_fake = prob_fake_smooth_global > ANTISPOOFING_THRESHOLD\n",
    "            last_antispoofing_result = (frame_is_fake, prob_fake_smooth_global)\n",
    "            \n",
    "            depth_colored = cv2.applyColorMap((depth_map_full * 255).astype(np.float32))\n",
    "            depth_colored = cv2.resize(depth_colored,(200,200))\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nel flusso anti-spoofing: {e}\")\n",
    "    else:\n",
    "        frame_is_fake,prob_fake_smooth_global = last_antispoofing_result\n",
    "        \n",
    "    ### Riconoscimento facciale e visualizzazione \n",
    "    for (x1,y1,x2,y2) in last_phone_dets:\n",
    "        cv2.rectangle(vis,(x1,y1),(x2,y2),(0,0,255),3)\n",
    "        cv2.putText(vis,f\"Telefono rilevato: {conf:.2f}\",(x1,y1-10),cv2.FONT_HERSHEY_COMPLEX,0.7,(0,0,255),2)\n",
    "        \n",
    "    if frame_is_fake:\n",
    "        cv2.rectangle(vis, (5, 5), (vis.shape[1]-5, 80), (0, 0, 255), -1)\n",
    "        cv2.putText(vis, f\" Frame falso ({prob_fake_smooth_global:.2f})\",(15, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    \n",
    "    if device_lock:\n",
    "        elapsed = time.time() - phone_lock_timestamp\n",
    "        \n",
    "        cv2.rectangle(vis, (5, 90), (vis.shape[1]-5, 150), (0, 0, 200), -1)\n",
    "        cv2.putText(vis, f\"  DISPOSITIVO RILEVATO - FR BLOCCATO\",\n",
    "                   (15, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(vis, f\" Lock attivo da {elapsed:.1f}s | Premi 'r' per sbloccare\",\n",
    "                   (15, 145), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    else:\n",
    "        fr_results = recognize_face_from_frame(frame,db,FACE_RECOGNITION_THRESHOLD)\n",
    "        \n",
    "        for (x1,y1,x2,y2), label, name, score in fr_results:\n",
    "            if name != \"Sconosciuto\":\n",
    "                if frame_is_fake:\n",
    "                    label = f\"Fake {name} ({prob_fake_smooth_global:.2f})\"\n",
    "                    color = (0,0,255)\n",
    "                else:\n",
    "                    \n",
    "                    label = f\"{name} ({1-prob_fake_smooth_global:.2f})\"\n",
    "                    color = (0,255,0)\n",
    "            else:\n",
    "                should_webhook = True\n",
    "                color = (0,165,255)\n",
    "                label = f\"Sconodciuto: {conf}\"\n",
    "            \n",
    "            cv2.rectangle(vis, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(vis, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            \n",
    "    # Chiamata webhook verso n8n\n",
    "    if should_webhook:\n",
    "        create_presence(name=name,recognition_score=score)\n",
    "        break\n",
    "    \n",
    "    # Comandi da tastiera\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r'):\n",
    "        if device_lock:\n",
    "            device_lock = False\n",
    "            last_phone_dets = []\n",
    "            print(\" Lock resettato manualmente\")\n",
    "        else:\n",
    "            print(\" Lock già disattivato\")\n",
    "    \n",
    "    frame_idx += 1\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"\\n  Sistema terminato\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rieux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
