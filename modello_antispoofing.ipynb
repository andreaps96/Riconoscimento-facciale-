{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xUWDOuz8TNfn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import models\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "from torchinfo import summary\n",
        "from torch.cuda.amp import GradScaler\n",
        "\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5O4LiglUNLE",
        "outputId": "6196cf4c-b93f-4364-8d09-1d349af8749e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V3HSlY9cq-W"
      },
      "source": [
        "### Definizione del Dataset e Caricamento dei Dati\n",
        "\n",
        "In questa sezione, prepariamo il nostro dataset per l'addestramento e la valutazione del modello. Le operazioni principali sono:\n",
        "\n",
        "1.  **Configurazione Iniziale**: Vengono definiti i percorsi (`root_color_train`, `root_depth_test`, ecc.) alle directory contenenti le immagini a colori e le mappe di profondità. Vengono inoltre impostati gli iperparametri fondamentali come la dimensione delle immagini (`img_size`), la grandezza dei batch (`batch_size`) e i parametri per l'ottimizzatore (`lr`, `weight_decay`).\n",
        "\n",
        "2.  **Creazione della Classe `AntiSpoofDataset`**: Poiché il nostro modello utilizza un input multimodale (**immagini RGB** e **mappe di profondità**), creiamo una classe `Dataset` personalizzata. Questa classe gestisce:\n",
        "    *   Il caricamento simultaneo di un'immagine a colori e della sua corrispondente mappa di profondità.\n",
        "    *   Il ridimensionamento di entrambe le immagini a una dimensione uniforme (`img_size`).\n",
        "    *   L'applicazione di trasformazioni e data augmentation (definite in una cella successiva).\n",
        "    *   La conversione delle immagini in tensori PyTorch pronti per essere inviati al modello.\n",
        "\n",
        "3.  **Funzione `load_paths` e Caricamento**: La funzione `load_paths` esamina le directory specificate, identifica i campioni come `real` (etichetta 0) o `fake` (etichetta 1) in base al nome del file e crea le liste di percorsi e etichette. Infine, questa funzione viene eseguita per caricare i dati di training e test, stampando un riepilogo del numero di campioni per ogni set e per ogni classe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eDJ6gxPgUZkl"
      },
      "outputs": [],
      "source": [
        "root_color_train = \"/content/drive/MyDrive/dataset_casia/train_img/color\"\n",
        "root_depth_train = \"/content/drive/MyDrive/dataset_casia/train_img/depth_midas_train\"\n",
        "\n",
        "root_color_test = \"/content/drive/MyDrive/dataset_casia/test_img/color\"\n",
        "root_depth_test = \"/content/drive/MyDrive/dataset_casia/test_img/depth_midas_test\"\n",
        "\n",
        "img_size = 224\n",
        "batch_size = 24\n",
        "lr = 1e-4\n",
        "weight_decay = 5e-4\n",
        "patience = 15\n",
        "use_mixed_precision = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPsbwVR6V0au",
        "outputId": "54680c5e-3e86-476e-d7d0-fe2063fb1ccd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Caricati 2408 campioni da /content/drive/MyDrive/dataset_casia/train_img/color\n",
            "Real: 591 | Fake: 1817\n",
            "Caricati 1655 campioni da /content/drive/MyDrive/dataset_casia/test_img/color\n",
            "Real: 404 | Fake: 1251\n",
            "\n",
            "Train: 2408 | Test: 1655\n"
          ]
        }
      ],
      "source": [
        "class AntiSpoofDataset(Dataset):\n",
        "    def __init__(self, color_paths, depth_paths, labels, transform=None):\n",
        "        self.color_paths = color_paths\n",
        "        self.depth_paths = depth_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.color_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Carica immagini\n",
        "        img = cv2.imread(self.color_paths[idx]) #(H,W,3)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #(H,W,3)\n",
        "        depth = cv2.imread(self.depth_paths[idx], cv2.IMREAD_GRAYSCALE) #(H,W)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        # Resize\n",
        "        img = cv2.resize(img, (img_size, img_size))\n",
        "        depth = cv2.resize(depth, (img_size, img_size))\n",
        "\n",
        "        if self.transform:\n",
        "            # Augmentation\n",
        "            #augmented è un dizionario in cui le immagini rgb e le corrispettive mappe (chiavi del dizionario) sono sottoposte alle stesse trasformazioni geometriche\n",
        "            augmented = self.transform(image=img, mask=depth) \n",
        "            img = augmented[\"image\"]    # Tensor [3, H, W] \n",
        "            depth = augmented[\"mask\"]   # Numpy [H, W] (valori uint8 [0-255])\n",
        "\n",
        "            # Se albumentations non converte da numpy a tensore, converto numpy → Tensor e normalizzo\n",
        "            if isinstance(depth, np.ndarray):\n",
        "                depth = torch.from_numpy(depth).float() / 255.0\n",
        "            #Se albumentations converte da numpy a tensore, normalizzo\n",
        "            else:\n",
        "                # Se albumentations già converte (versioni diverse)\n",
        "                depth = depth.float() / 255.0\n",
        "\n",
        "            depth = depth.unsqueeze(0)  # [1, H, W]\n",
        "        else:\n",
        "            # Senza augmentation\n",
        "            img = torch.from_numpy(img.transpose(2, 0, 1)).float() / 255.0 #(H,W,3) --> (3,H,W)\n",
        "            depth = torch.from_numpy(depth).float() / 255.0\n",
        "            depth = depth.unsqueeze(0)\n",
        "\n",
        "        return img, depth, label\n",
        "\n",
        "\n",
        "def load_paths(root_color, root_depth):\n",
        "    color_paths, depth_paths, labels = [], [], []\n",
        "\n",
        "    for f in os.listdir(root_color):\n",
        "        if not f.lower().endswith((\".jpg\", \".png\")):\n",
        "            continue\n",
        "        f_lower = f.lower()\n",
        "\n",
        "        if \"real\" in f_lower:\n",
        "            label = 0\n",
        "        elif \"fake\" in f_lower:\n",
        "            label = 1\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        color_path = os.path.join(root_color, f)\n",
        "        depth_path = os.path.join(root_depth, f)\n",
        "\n",
        "        if os.path.exists(depth_path):\n",
        "            color_paths.append(color_path)\n",
        "            depth_paths.append(depth_path)\n",
        "            labels.append(label)\n",
        "\n",
        "    print(f\"Caricati {len(color_paths)} campioni da {root_color}\")\n",
        "    print(f\"Real: {labels.count(0)} | Fake: {labels.count(1)}\")\n",
        "    return color_paths, depth_paths, labels\n",
        "\n",
        "\n",
        "train_color, train_depth, train_labels = load_paths(root_color_train, root_depth_train)\n",
        "test_color, test_depth, test_labels = load_paths(root_color_test, root_depth_test)\n",
        "\n",
        "print(f\"\\nTrain: {len(train_color)} | Test: {len(test_color)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUgeizVycq-X"
      },
      "source": [
        "### Data Augmentation e Creazione dei DataLoader\n",
        "\n",
        "Questa cella si occupa di due compiti fondamentali: definire le strategie di data augmentation e creare i `DataLoader` di PyTorch, che preparano i dati in lotti (batch) per l'addestramento e la valutazione.\n",
        "\n",
        "#### Data Augmentation con Albumentations\n",
        "Per rendere il modello più robusto e capace di generalizzare a condizioni del mondo reale, viene applicata una pipeline di **data augmentation** molto ricca al solo set di addestramento, utilizzando la libreria `Albumentations`. Le trasformazioni sono state scelte per simulare scenari di attacco comuni:\n",
        "\n",
        "-   **Variazioni di Illuminazione**: `RandomBrightnessContrast`, `RandomGamma` e `HueSaturationValue` per simulare diverse condizioni di luce ambientale.\n",
        "-   **Artefatti di Display/Stampa**: `GaussNoise`, `ISONoise`, `MotionBlur` e `GaussianBlur` per imitare il rumore e le sfocature introdotte da schermi, proiettori o stampe di bassa qualità.\n",
        "-   **Diverse Angolazioni e Prospettive**: `ShiftScaleRotate` e `Perspective` per simulare riprese del volto da diverse angolazioni.\n",
        "-   **Qualità del Sensore**: `CLAHE` e `Sharpen` per simulare l'effetto di diverse fotocamere.\n",
        "\n",
        "L'argomento `additional_targets={'mask': 'mask'}` è cruciale: garantisce che le trasformazioni geometriche (come rotazioni o ritagli) vengano applicate in modo identico sia all'immagine RGB sia alla mappa di profondità, mantenendole perfettamente allineate.\n",
        "\n",
        "Il set di test, invece, subisce solo la normalizzazione e la conversione in tensore per garantire una valutazione oggettiva e riproducibile delle performance del modello.\n",
        "\n",
        "#### Gestione dello Sbilanciamento delle Classi\n",
        "Come osservato in precedenza, il dataset è sbilanciato, con un numero maggiore di campioni \"fake\". Per evitare che il modello diventi \"pigro\" e prediliga la classe maggioritaria, viene utilizzato un `WeightedRandomSampler`. Questo campionatore assegna un peso maggiore ai campioni della classe meno rappresentata (in questo caso, \"real\"), assicurando che durante l'addestramento il modello veda un numero più bilanciato di esempi per ogni classe.\n",
        "\n",
        "#### Creazione dei DataLoader\n",
        "Infine, vengono creati i `DataLoader` per i set di training e test. Questi oggetti gestiscono il caricamento efficiente dei dati in batch, sfruttando il campionatore pesato per il training e mantenendo l'ordine sequenziale per il testing (`shuffle=False`). L'opzione `pin_memory=True` viene usata per velocizzare il trasferimento dei dati sulla GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CDiZoDgsZo9g"
      },
      "outputs": [],
      "source": [
        "train_tf = A.Compose([\n",
        "    # Simula diverse condizioni di illuminazione\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=0.7),\n",
        "    A.RandomGamma(gamma_limit=(70, 130), p=0.5),\n",
        "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.6),\n",
        "\n",
        "    # Simula artefatti di stampa/display\n",
        "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.4),\n",
        "    A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.3),\n",
        "    A.MotionBlur(blur_limit=7, p=0.4),\n",
        "    A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
        "\n",
        "    # Simula diverse angolazioni\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=20, p=0.6),\n",
        "    A.Perspective(scale=(0.05, 0.1), p=0.4),\n",
        "\n",
        "    # Simula diversi dispositivi di cattura\n",
        "    A.CLAHE(clip_limit=2.0, p=0.3),\n",
        "    A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.3),\n",
        "\n",
        "    # Augmentazioni base\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n",
        "\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "], additional_targets={'mask': 'mask'})\n",
        "\n",
        "\n",
        "test_tf = A.Compose([\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "], additional_targets={'mask': 'mask'})\n",
        "\n",
        "train_dataset = AntiSpoofDataset(train_color,train_depth,train_labels,train_tf)\n",
        "test_dataset = AntiSpoofDataset(test_color,test_depth,test_labels,test_tf)\n",
        "\n",
        "class_counts = [train_labels.count(0), train_labels.count(1)]\n",
        "class_weights = [1.0 / c for c in class_counts]\n",
        "sample_weights = [class_weights[label] for label in train_labels]\n",
        "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, num_workers=2,pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2,pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjBmR7q0cq-Y"
      },
      "source": [
        "### Architettura del Modello Anti-Spoofing\n",
        "\n",
        "Questa sezione definisce l'architettura completa del nostro modello di classificazione. Il design si basa su un approccio **multimodale** che sfrutta sia le informazioni cromatiche (RGB) sia quelle di profondità per massimizzare l'accuratezza. L'architettura è composta da diversi moduli chiave:\n",
        "\n",
        "#### `RGBEncoder`\n",
        "Questo modulo è responsabile dell'elaborazione delle immagini a colori. La sua architettura è così strutturata:\n",
        "-   **Backbone**: Utilizza le feature convoluzionali di **EfficientNet-B0**, pre-addestrato su ImageNet. Questa scelta fornisce un potente estrattore di feature senza un costo computazionale eccessivo.\n",
        "-   **`ChannelAttention`**: Dopo l'estrazione delle feature, viene applicato un meccanismo di attenzione sui canali. Questo modulo, ispirato a CBAM (Convolutional Block Attention Module), impara a pesare dinamicamente i canali delle feature map, permettendo al modello di concentrarsi sulle informazioni più rilevanti e sopprimere quelle meno utili.\n",
        "-   **Head di Proiezione**: Le feature raffinate vengono poi processate da un blocco di classificazione (head) composto da strati lineari, normalizzazione e dropout, che le proietta in uno spazio latente a 128 dimensioni.\n",
        "\n",
        "#### `DepthEncoder`\n",
        "Questo modulo, progettato su misura, elabora le mappe di profondità in scala di grigi. La sua architettura è pensata per catturare informazioni a diverse scale:\n",
        "-   **Feature Extractor Multi-Scala**: Consiste in una serie di blocchi convoluzionali che estraggono feature a risoluzioni decrescenti (`f1`, `f2`, `f3`).\n",
        "-   **Fusione Multi-Scala**: Le feature map estratte a diverse profondità vengono ridimensionate alla stessa risoluzione spaziale e concatenate. Questo permette al modello di combinare dettagli fini (da feature map a risoluzione più alta) con informazioni contestuali più ampie (da feature map a risoluzione più bassa).\n",
        "-   **Head di Proiezione**: Similmente all'encoder RGB, un blocco finale proietta le feature di profondità fuse in uno spazio latente a 128 dimensioni.\n",
        "\n",
        "#### `CrossModalAttention`\n",
        "Questo è il cuore dell'interazione tra le due modalità. Vengono utilizzati due moduli di attenzione incrociata:\n",
        "1.  **`rgb_to_depth`**: Usa le feature RGB come *query* e le feature di profondità come *key* e *value*. In pratica, \"chiede\" alle feature di profondità quali siano le più rilevanti per contestualizzare le informazioni RGB.\n",
        "2.  **`depth_to_rgb`**: Fa l'opposto, usando la profondità come *query* per pesare le feature RGB.\n",
        "\n",
        "Questo meccanismo permette a ciascuna modalità di arricchirsi con le informazioni complementari fornite dall'altra.\n",
        "\n",
        "#### `AntiSpoofingModel` (Modello Principale)\n",
        "Il modello finale assembla i componenti precedenti:\n",
        "1.  **Estrazione Indipendente**: Le immagini RGB e di profondità vengono processate dai rispettivi encoder per ottenere i vettori di feature iniziali (`rgb_feat`, `depth_feat`).\n",
        "2.  **Arricchimento Incrociato**: Vengono calcolate le feature \"attese\" (`rgb_attended`, `depth_attended`) tramite i moduli di `CrossModalAttention`.\n",
        "3.  **Concatenazione e Fusione**: I quattro vettori di feature (originali e attesi) vengono concatenati in un unico vettore di dimensione 512.\n",
        "4.  **Classificazione Finale**: Un blocco di fusione, composto da strati densi con dropout e normalizzazione, processa il vettore combinato per produrre le feature finali a 128 dimensioni. Infine, un classificatore lineare produce i *logit* per le due classi (\"real\" e \"fake\").\n",
        "\n",
        "Il modello può restituire opzionalmente anche le feature finali, utili per funzioni di loss più complesse come la loss contrastiva."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SI2a6Oa-cyU1"
      },
      "outputs": [],
      "source": [
        "class ChannelAttention(nn.Module):\n",
        "  def __init__(self,channels,reduction=16):\n",
        "    super().__init__()\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d(1) # pool medio globale\n",
        "    self.max_pool = nn.AdaptiveMaxPool2d(1) # pool max globale\n",
        "\n",
        "    #Bottleneck\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(channels,channels//reduction,bias=False),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(channels//reduction,channels,bias=False)\n",
        "    )\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x):\n",
        "    b, c, _, _ = x.size()\n",
        "    avg_out = self.avg_pool(x).view(b, c)  # [B, 1280, 7, 7] → [B, 1280, 1, 1] → [B, 1280]\n",
        "    max_out = self.max_pool(x).view(b, c)  # [B, 1280, 7, 7] → [B, 1280, 1, 1] → [B, 1280]\n",
        "    avg_out = self.fc(avg_out)  # [B, 1280] → [B, 80] → [B, 1280]\n",
        "    max_out = self.fc(max_out)  # [B, 1280] → [B, 80] → [B, 1280]\n",
        "    out = self.sigmoid(avg_out + max_out)  # [B, 1280] → somma → sigmoid\n",
        "    out = out.view(b, c, 1, 1)              # [B, 1280, 1, 1]\n",
        "    return x * out  # [B, 1280, 7, 7] * [B, 1280, 1, 1] → [B, 1280, 7, 7]\n",
        "\n",
        "\n",
        "class RGBEncoder(nn.Module):\n",
        "  def __init__(self,output_dim=128):\n",
        "    super().__init__()\n",
        "\n",
        "    base = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    #backbone dell'encoder RGB --> EfficentNet-B0 net addestrato su ImageNet ([B,3,224,224] --> [B,1280,7,7])\n",
        "    self.feature_extractor = base.features\n",
        "    #([B,1280,7,7] --> [B,1280,7,7])\n",
        "    self.attention = ChannelAttention(1280)\n",
        "    # ([B,1280],[B120])\n",
        "    self.head = nn.Sequential(\n",
        "        nn.Linear(1280, 256),\n",
        "        nn.BatchNorm1d(256),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(256, 128)\n",
        "    )\n",
        "\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.feature_extractor(x)\n",
        "    x = self.attention(x)\n",
        "    x = F.adaptive_avg_pool2d(x,1).flatten(1) #([B,1280,7,7] --> [B,1280])\n",
        "    return self.head(x)\n",
        "\n",
        "class DepthEncoder(nn.Module):\n",
        "  def __init__(self,output_dim=128):\n",
        "    super().__init__()\n",
        "\n",
        "    # [B,1,224,224] → [B,32,112,112]\n",
        "    self.depth1 = nn.Sequential(\n",
        "        nn.Conv2d(1,32,3,2,1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32,32,3,1,1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    # [B,32,112,112] --> [B,64,56,56]\n",
        "    self.depth2 = nn.Sequential(\n",
        "        nn.Conv2d(32,64,3,2,1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64,64,3,1,1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    # [B,64,56,56] --> [B,128,28,28]\n",
        "    self.depth3 = nn.Sequential(\n",
        "        nn.Conv2d(64,128,3,2,1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.fusion = nn.Sequential(\n",
        "        nn.Conv2d(224,128,1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.upsample1 = nn.Upsample(scale_factor=4,mode='bilinear',align_corners=False)\n",
        "    self.upsample2 = nn.Upsample(scale_factor=2,mode='bilinear',align_corners=False)\n",
        "\n",
        "    self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(128,128)\n",
        "    )\n",
        "\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "  def forward(self,x):\n",
        "    f1 = self.depth1(x)   # [B,1,224,224] → [B,32,112,112]\n",
        "    f2 = self.depth2(f1)  # Usa f1 (32 canali)\n",
        "    f3 = self.depth3(f2)  # Usa f2 (64 canali)\n",
        "\n",
        "    f1_up = self.upsample1(f1) # [B,32,112,112] --> [B,32,448,448]\n",
        "    f2_up = self.upsample2(f2) # [B,64,56,56] --> [B,64,112,112]\n",
        "\n",
        "    target_size = f3.shape[2:] # (28,28)\n",
        "    f1_up = F.interpolate(f1_up,size=target_size,mode='bilinear',align_corners=False) # [B,32,448,448] --> [b,32,64,64]\n",
        "    f2_up = F.interpolate(f2_up,size=target_size,mode='bilinear',align_corners=False) # [B,64,112,112] --> [B,64,28,28]\n",
        "\n",
        "    #concatenazione multi-scala\n",
        "    multi_scale = torch.cat([f1_up,f2_up,f3],dim=1) # [B,32,28,28] + [B,64,28,28] + [B,128,28,28] = [B,224,28,28]\n",
        "\n",
        "    fused = self.fusion(multi_scale) # [B,224,28,28] --> [B,128,28,28]\n",
        "\n",
        "    x = F.adaptive_avg_pool2d(fused, 1).flatten(1)  # [B,128,28,28] → [B,128]\n",
        "    return self.fc(x)  # [B,128]\n",
        "\n",
        "\n",
        "class CrossModalAttention(nn.Module):\n",
        "  def __init__(self,dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.query = nn.Linear(dim,dim)\n",
        "    self.key = nn.Linear(dim,dim)\n",
        "    self.value = nn.Linear(dim,dim)\n",
        "    self.scale = dim ** -0.5\n",
        "    self.out_proj = nn.Linear(dim, dim)\n",
        "\n",
        "  def forward(self,rgb_x,depth_x):\n",
        "    q = self.query(rgb_x).unsqueeze(1) # [B, 128] → [B, 1, 128]\n",
        "    k = self.key(depth_x).unsqueeze(1) # [B, 128] → [B, 1, 128]\n",
        "    v = self.value(depth_x).unsqueeze(1) # [B, 128] → [B, 1, 128]\n",
        "\n",
        "    attn = (q @ k.transpose(-2,-1)) * self.scale\n",
        "    attn = F.softmax(attn,dim=-1) # normalizzo in [0,1]\n",
        "    out = (attn @ v).squeeze(1)  # [B, 1, 1] @ [B, 1, 128] → [B, 128]\n",
        "    return self.out_proj(out)\n",
        "\n",
        "\n",
        "class AntiSpoofingModel(nn.Module):\n",
        "  def __init__(self,rgb_encoder,depth_encoder):\n",
        "    super().__init__()\n",
        "    self.rgb_encoder = rgb_encoder\n",
        "    self.depth_encoder = depth_encoder\n",
        "\n",
        "    self.rgb_to_depth = CrossModalAttention(rgb_encoder.output_dim)\n",
        "    self.depth_to_rgb = CrossModalAttention(depth_encoder.output_dim)\n",
        "\n",
        "    fusion_dim = rgb_encoder.output_dim * 2 + depth_encoder.output_dim * 2\n",
        "    self.fusion = nn.Sequential(\n",
        "        nn.Linear(fusion_dim, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.BatchNorm1d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.4),\n",
        "        nn.Linear(256, 128),\n",
        "        nn.BatchNorm1d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Linear(128,2)\n",
        "\n",
        "  def forward(self,rgb_x,depth_x,return_features=False):\n",
        "    rgb_feat = self.rgb_encoder(rgb_x)\n",
        "    depth_feat = self.depth_encoder(depth_x)\n",
        "\n",
        "    rgb_attended = self.rgb_to_depth(rgb_feat,depth_feat)\n",
        "    depth_attended = self.depth_to_rgb(depth_feat,rgb_feat)\n",
        "\n",
        "    x = torch.cat(\n",
        "        [\n",
        "            rgb_feat,rgb_attended,\n",
        "            depth_feat,depth_attended\n",
        "        ],\n",
        "        dim=1\n",
        "    )\n",
        "\n",
        "    features = self.fusion(x)\n",
        "    logits = self.classifier(features)\n",
        "\n",
        "    if return_features:\n",
        "            return logits, features\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWOxCQN3Ga0G",
        "outputId": "b58511a4-b793-4af3-888c-2117accddfa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 239MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "================================================================================================================================================================\n",
              "Layer (type:depth-idx)                                       Input Shape               Output Shape              Param #                   Trainable\n",
              "================================================================================================================================================================\n",
              "AntiSpoofingModel                                            [1, 3, 224, 224]          [1, 2]                    --                        True\n",
              "├─RGBEncoder: 1-1                                            [1, 3, 224, 224]          [1, 128]                  --                        True\n",
              "│    └─Sequential: 2-1                                       [1, 3, 224, 224]          [1, 1280, 7, 7]           --                        True\n",
              "│    │    └─Conv2dNormActivation: 3-1                        [1, 3, 224, 224]          [1, 32, 112, 112]         928                       True\n",
              "│    │    └─Sequential: 3-2                                  [1, 32, 112, 112]         [1, 16, 112, 112]         1,448                     True\n",
              "│    │    └─Sequential: 3-3                                  [1, 16, 112, 112]         [1, 24, 56, 56]           16,714                    True\n",
              "│    │    └─Sequential: 3-4                                  [1, 24, 56, 56]           [1, 40, 28, 28]           46,640                    True\n",
              "│    │    └─Sequential: 3-5                                  [1, 40, 28, 28]           [1, 80, 14, 14]           242,930                   True\n",
              "│    │    └─Sequential: 3-6                                  [1, 80, 14, 14]           [1, 112, 14, 14]          543,148                   True\n",
              "│    │    └─Sequential: 3-7                                  [1, 112, 14, 14]          [1, 192, 7, 7]            2,026,348                 True\n",
              "│    │    └─Sequential: 3-8                                  [1, 192, 7, 7]            [1, 320, 7, 7]            717,232                   True\n",
              "│    │    └─Conv2dNormActivation: 3-9                        [1, 320, 7, 7]            [1, 1280, 7, 7]           412,160                   True\n",
              "│    └─ChannelAttention: 2-2                                 [1, 1280, 7, 7]           [1, 1280, 7, 7]           --                        True\n",
              "│    │    └─AdaptiveAvgPool2d: 3-10                          [1, 1280, 7, 7]           [1, 1280, 1, 1]           --                        --\n",
              "│    │    └─AdaptiveMaxPool2d: 3-11                          [1, 1280, 7, 7]           [1, 1280, 1, 1]           --                        --\n",
              "│    │    └─Sequential: 3-12                                 [1, 1280]                 [1, 1280]                 204,800                   True\n",
              "│    │    └─Sequential: 3-13                                 [1, 1280]                 [1, 1280]                 (recursive)               True\n",
              "│    │    └─Sigmoid: 3-14                                    [1, 1280]                 [1, 1280]                 --                        --\n",
              "│    └─Sequential: 2-3                                       [1, 1280]                 [1, 128]                  --                        True\n",
              "│    │    └─Linear: 3-15                                     [1, 1280]                 [1, 256]                  327,936                   True\n",
              "│    │    └─BatchNorm1d: 3-16                                [1, 256]                  [1, 256]                  512                       True\n",
              "│    │    └─ReLU: 3-17                                       [1, 256]                  [1, 256]                  --                        --\n",
              "│    │    └─Dropout: 3-18                                    [1, 256]                  [1, 256]                  --                        --\n",
              "│    │    └─Linear: 3-19                                     [1, 256]                  [1, 128]                  32,896                    True\n",
              "├─DepthEncoder: 1-2                                          [1, 1, 224, 224]          [1, 128]                  --                        True\n",
              "│    └─Sequential: 2-4                                       [1, 1, 224, 224]          [1, 32, 112, 112]         --                        True\n",
              "│    │    └─Conv2d: 3-20                                     [1, 1, 224, 224]          [1, 32, 112, 112]         320                       True\n",
              "│    │    └─BatchNorm2d: 3-21                                [1, 32, 112, 112]         [1, 32, 112, 112]         64                        True\n",
              "│    │    └─ReLU: 3-22                                       [1, 32, 112, 112]         [1, 32, 112, 112]         --                        --\n",
              "│    │    └─Conv2d: 3-23                                     [1, 32, 112, 112]         [1, 32, 112, 112]         9,248                     True\n",
              "│    │    └─BatchNorm2d: 3-24                                [1, 32, 112, 112]         [1, 32, 112, 112]         64                        True\n",
              "│    │    └─ReLU: 3-25                                       [1, 32, 112, 112]         [1, 32, 112, 112]         --                        --\n",
              "│    └─Sequential: 2-5                                       [1, 32, 112, 112]         [1, 64, 56, 56]           --                        True\n",
              "│    │    └─Conv2d: 3-26                                     [1, 32, 112, 112]         [1, 64, 56, 56]           18,496                    True\n",
              "│    │    └─BatchNorm2d: 3-27                                [1, 64, 56, 56]           [1, 64, 56, 56]           128                       True\n",
              "│    │    └─ReLU: 3-28                                       [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n",
              "│    │    └─Conv2d: 3-29                                     [1, 64, 56, 56]           [1, 64, 56, 56]           36,928                    True\n",
              "│    │    └─BatchNorm2d: 3-30                                [1, 64, 56, 56]           [1, 64, 56, 56]           128                       True\n",
              "│    │    └─ReLU: 3-31                                       [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n",
              "│    └─Sequential: 2-6                                       [1, 64, 56, 56]           [1, 128, 28, 28]          --                        True\n",
              "│    │    └─Conv2d: 3-32                                     [1, 64, 56, 56]           [1, 128, 28, 28]          73,856                    True\n",
              "│    │    └─BatchNorm2d: 3-33                                [1, 128, 28, 28]          [1, 128, 28, 28]          256                       True\n",
              "│    │    └─ReLU: 3-34                                       [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n",
              "│    └─Upsample: 2-7                                         [1, 32, 112, 112]         [1, 32, 448, 448]         --                        --\n",
              "│    └─Upsample: 2-8                                         [1, 64, 56, 56]           [1, 64, 112, 112]         --                        --\n",
              "│    └─Sequential: 2-9                                       [1, 224, 28, 28]          [1, 128, 28, 28]          --                        True\n",
              "│    │    └─Conv2d: 3-35                                     [1, 224, 28, 28]          [1, 128, 28, 28]          28,800                    True\n",
              "│    │    └─BatchNorm2d: 3-36                                [1, 128, 28, 28]          [1, 128, 28, 28]          256                       True\n",
              "│    │    └─ReLU: 3-37                                       [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n",
              "│    └─Sequential: 2-10                                      [1, 128]                  [1, 128]                  --                        True\n",
              "│    │    └─Linear: 3-38                                     [1, 128]                  [1, 128]                  16,512                    True\n",
              "├─CrossModalAttention: 1-3                                   [1, 128]                  [1, 128]                  --                        True\n",
              "│    └─Linear: 2-11                                          [1, 128]                  [1, 128]                  16,512                    True\n",
              "│    └─Linear: 2-12                                          [1, 128]                  [1, 128]                  16,512                    True\n",
              "│    └─Linear: 2-13                                          [1, 128]                  [1, 128]                  16,512                    True\n",
              "│    └─Linear: 2-14                                          [1, 128]                  [1, 128]                  16,512                    True\n",
              "├─CrossModalAttention: 1-4                                   [1, 128]                  [1, 128]                  --                        True\n",
              "│    └─Linear: 2-15                                          [1, 128]                  [1, 128]                  16,512                    True\n",
              "│    └─Linear: 2-16                                          [1, 128]                  [1, 128]                  16,512                    True\n",
              "│    └─Linear: 2-17                                          [1, 128]                  [1, 128]                  16,512                    True\n",
              "│    └─Linear: 2-18                                          [1, 128]                  [1, 128]                  16,512                    True\n",
              "├─Sequential: 1-5                                            [1, 512]                  [1, 128]                  --                        True\n",
              "│    └─Linear: 2-19                                          [1, 512]                  [1, 512]                  262,656                   True\n",
              "│    └─BatchNorm1d: 2-20                                     [1, 512]                  [1, 512]                  1,024                     True\n",
              "│    └─ReLU: 2-21                                            [1, 512]                  [1, 512]                  --                        --\n",
              "│    └─Dropout: 2-22                                         [1, 512]                  [1, 512]                  --                        --\n",
              "│    └─Linear: 2-23                                          [1, 512]                  [1, 256]                  131,328                   True\n",
              "│    └─BatchNorm1d: 2-24                                     [1, 256]                  [1, 256]                  512                       True\n",
              "│    └─ReLU: 2-25                                            [1, 256]                  [1, 256]                  --                        --\n",
              "│    └─Dropout: 2-26                                         [1, 256]                  [1, 256]                  --                        --\n",
              "│    └─Linear: 2-27                                          [1, 256]                  [1, 128]                  32,896                    True\n",
              "│    └─BatchNorm1d: 2-28                                     [1, 128]                  [1, 128]                  256                       True\n",
              "│    └─ReLU: 2-29                                            [1, 128]                  [1, 128]                  --                        --\n",
              "│    └─Dropout: 2-30                                         [1, 128]                  [1, 128]                  --                        --\n",
              "├─Linear: 1-6                                                [1, 128]                  [1, 2]                    258                       True\n",
              "================================================================================================================================================================\n",
              "Total params: 5,319,774\n",
              "Trainable params: 5,319,774\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 760.25\n",
              "================================================================================================================================================================\n",
              "Input size (MB): 0.80\n",
              "Forward/backward pass size (MB): 130.41\n",
              "Params size (MB): 21.28\n",
              "Estimated Total Size (MB): 152.49\n",
              "================================================================================================================================================================"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = AntiSpoofingModel(\n",
        "    RGBEncoder(),\n",
        "    DepthEncoder()\n",
        ").to(device)\n",
        "\n",
        "summary(\n",
        "    model,\n",
        "    input_data=[\n",
        "        torch.randn(1, 3, 224, 224).to(device),   # RGB input\n",
        "        torch.randn(1, 1, 224, 224).to(device)    # Depth input\n",
        "    ],\n",
        "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "    depth=3,\n",
        "    verbose=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV9xewdPcq-Y"
      },
      "source": [
        "### Funzione di Loss Ibrida: `ContrastativeFocalLoss`\n",
        "\n",
        "Per addestrare efficacemente il nostro modello, non ci affidiamo a una semplice Cross-Entropy, ma implementiamo una **funzione di loss ibrida** personalizzata che combina due potenti concetti: la **Focal Loss** e la **Contrastive Loss**. Questa scelta è motivata dalla necessità di affrontare due sfide comuni: lo sbilanciamento delle classi e la difficoltà nel distinguere esempi \"difficili\".\n",
        "\n",
        "#### Focal Loss\n",
        "La componente `focal_loss` affronta il problema dello sbilanciamento delle classi e la presenza di esempi \"facili\" e \"difficili\". A differenza della Cross-Entropy standard, la Focal Loss riduce dinamicamente il peso degli esempi che il modello classifica già correttamente (quelli \"facili\"). Questo permette all'ottimizzatore di **concentrarsi sugli esempi più difficili e informativi**, che sono spesso quelli al confine tra le classi \"real\" e \"fake\". I parametri chiave sono:\n",
        "-   `alpha`: Pesa l'importanza delle classi positive/negative.\n",
        "-   `gamma`: Modula la focalizzazione; un `gamma` più alto aumenta l'effetto di down-weighting sugli esempi facili.\n",
        "\n",
        "#### Contrastive Loss (Supervised)\n",
        "La componente `contrastive_loss` opera non sui *logit* finali, ma direttamente sullo **spazio delle feature** a 128 dimensioni prodotte dal modello. L'obiettivo è quello di strutturare questo spazio latente in modo che sia semanticamente significativo. In particolare, questa loss:\n",
        "-   **Avvicina** le feature di campioni appartenenti alla stessa classe (es. due volti \"real\" diversi).\n",
        "-   **Allontana** le feature di campioni appartenenti a classi diverse (es. un volto \"real\" e uno \"fake\").\n",
        "\n",
        "Questo approccio, noto come *Supervised Contrastive Learning*, aiuta il modello a imparare rappresentazioni più robuste e discriminative, migliorando la sua capacità di generalizzazione. Il parametro `temperature` controlla la separazione tra le classi nello spazio latente.\n",
        "\n",
        "#### Combinazione\n",
        "La loss finale è una somma pesata delle due componenti:\n",
        "`Total Loss = focal_loss + contrast_weight * contrastive_loss`\n",
        "\n",
        "Durante l'**addestramento**, vengono utilizzate entrambe le componenti per ottimizzare sia la classificazione sia la struttura dello spazio delle feature. Durante la **valutazione**, viene usata solo la `focal_loss` per calcolare una metrica di performance coerente, poiché la componente contrastiva dipende dalla composizione del batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5m8dYaSrelvD"
      },
      "outputs": [],
      "source": [
        "class ContrastativeFocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2.0, contrast_weight=0.3, temperature=0.5):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.contrast_weight = contrast_weight\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def focal_loss(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "    def contrastive_loss(self, features, labels):\n",
        "        # Normalizza features per calcolare similarità\n",
        "        features = F.normalize(features, dim=1)\n",
        "\n",
        "        # Matrice di similarità (cosine similarity)\n",
        "        sim_matrix = torch.matmul(features, features.T) / self.temperature\n",
        "\n",
        "        # Maschera per positive pairs (stessa classe)\n",
        "        labels = labels.view(-1, 1)\n",
        "        mask = torch.eq(labels, labels.T).float().to(features.device)\n",
        "\n",
        "        # Rimuovi diagonale (non confrontare sample con se stesso)\n",
        "        mask = mask - torch.eye(mask.size(0)).to(features.device)\n",
        "\n",
        "        # Contrastive loss: avvicina same-class, allontana different-class\n",
        "        exp_sim = torch.exp(sim_matrix)\n",
        "        log_prob = sim_matrix - torch.log(exp_sim.sum(1, keepdim=True) + 1e-8)\n",
        "\n",
        "        # Media solo sui positive pairs\n",
        "        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-8)\n",
        "        loss = -mean_log_prob_pos.mean()\n",
        "        return loss\n",
        "\n",
        "    def forward(self, logits, features=None, targets=None):\n",
        "        # Caso: criterion(out, y)\n",
        "        if targets is None and features is not None and features.dtype == torch.long:\n",
        "            targets = features\n",
        "            features = None\n",
        "\n",
        "        # Solo focal loss (test)\n",
        "        if features is None:\n",
        "            return self.focal_loss(logits, targets)\n",
        "\n",
        "        # Focal + contrastive (train)\n",
        "        focal = self.focal_loss(logits, targets)\n",
        "        contrastive = self.contrastive_loss(features, targets)\n",
        "        return focal + self.contrast_weight * contrastive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcMfJjAvcq-Z"
      },
      "source": [
        "### Ottimizzatore, Scheduler e Early Stopping\n",
        "\n",
        "In questa sezione, configuriamo tutti gli strumenti necessari per il processo di addestramento: l'ottimizzatore che aggiorna i pesi del modello, lo scheduler che gestisce il learning rate e un meccanismo di early stopping per prevenire l'overfitting e salvare il modello migliore.\n",
        "\n",
        "#### Ottimizzatore e Funzione di Loss\n",
        "-   **Ottimizzatore `AdamW`**: È stata scelta una variante dell'ottimizzatore Adam, nota come AdamW. A differenza di Adam classico, AdamW disaccoppia il meccanismo di weight decay dalla gradiente, portando spesso a una migliore generalizzazione e performance più stabili. L'opzione `amsgrad` è attivata per migliorare ulteriormente la convergenza.\n",
        "-   **Istanza della Loss**: Viene creata un'istanza della nostra funzione di loss personalizzata, `ContrastativeFocalLoss`, con i parametri `alpha`, `gamma` e `contrast_weight` specificati.\n",
        "\n",
        "#### Scheduler del Learning Rate: `CosineAnnealingWarmRestarts`\n",
        "Per evitare di rimanere bloccati in minimi locali e per esplorare meglio lo spazio della loss, viene utilizzato uno scheduler avanzato. Il `CosineAnnealingWarmRestarts` varia ciclicamente il learning rate (LR) seguendo un andamento cosinusoidale:\n",
        "-   **Decadimento Coseno**: L'LR diminuisce gradualmente da un valore massimo a un valore minimo (`eta_min`) in un certo numero di epoche (`T_0`).\n",
        "-   **Warm Restarts**: Al termine di ogni ciclo, l'LR viene \"resettato\" al suo valore iniziale. Questo \"calcio\" aiuta il modello a uscire da eventuali plateau e a convergere verso soluzioni migliori.\n",
        "-   **Cicli Crescenti**: Il parametro `T_mult=2` fa sì che la durata di ogni ciclo successivo raddoppi, permettendo al modello di affinare la sua convergenza man mano che l'addestramento procede.\n",
        "\n",
        "#### Classe `EarlyStopping`\n",
        "Per evitare di addestrare il modello più del necessario (rischiando overfitting e spreco di tempo), viene implementata una classe `EarlyStopping`. Questa utility monitora una metrica di performance sul set di validazione (nel nostro caso, l'F1-score) e interrompe l'addestramento se non si osservano miglioramenti per un numero specificato di epoche (`patience`).\n",
        "\n",
        "Le sue responsabilità principali sono:\n",
        "-   **Monitorare lo Score**: Confronta lo score dell'epoca corrente con il miglior score ottenuto finora.\n",
        "-   **Salvare il Modello Migliore**: Se viene raggiunto un nuovo score migliore, salva un checkpoint del modello, dello stato dell'ottimizzatore e delle metriche correnti.\n",
        "-   **Interrompere l'Addestramento**: Se non ci sono miglioramenti per `patience` epoche consecutive, imposta un flag per terminare il ciclo di training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qsFpWx0gLQJh"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=15, min_delta=0, mode='max', save_path='best_model.pth'):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.mode = mode\n",
        "        self.save_path = save_path\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, score, model, optimizer, epoch, **kwargs):  #  Aggiunto **kwargs\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(model, optimizer, epoch, score, **kwargs)\n",
        "            return False\n",
        "\n",
        "        # Fix logica improved\n",
        "        if self.mode == \"max\":\n",
        "            improved = score > (self.best_score + self.min_delta)\n",
        "        else:  # mode == \"min\"\n",
        "            improved = score < (self.best_score - self.min_delta)  #  Corretto\n",
        "\n",
        "        if improved:\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "            self.save_checkpoint(model, optimizer, epoch, score, **kwargs)\n",
        "            return False\n",
        "        else:\n",
        "            self.counter += 1  # Aggiunto self.\n",
        "            print(f\"Nessun miglioramento (counter {self.counter}/{self.patience})\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "                return True\n",
        "            return False\n",
        "\n",
        "    def save_checkpoint(self, model, optimizer, epoch, score, **kwargs):\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'score': score,\n",
        "            **kwargs\n",
        "        }\n",
        "        torch.save(checkpoint, self.save_path)\n",
        "        print(f\"Checkpoint salvato! Score: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jhvBXuhM_H6e"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.AdamW(\n",
        "  model.parameters(),\n",
        "  lr,\n",
        "  betas=(0.9, 0.999),\n",
        "  weight_decay=weight_decay,\n",
        "  amsgrad=True\n",
        ")\n",
        "\n",
        "scheduler = CosineAnnealingWarmRestarts(\n",
        "    optimizer,\n",
        "    T_0=10,  # Restart ogni 10 epochs\n",
        "    T_mult=2,\n",
        "    eta_min=1e-6\n",
        ")\n",
        "\n",
        "criterion = ContrastativeFocalLoss(\n",
        "    alpha=0.25,\n",
        "    gamma=2.0,\n",
        "    contrast_weight=0.3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucD7zXXVcq-Z"
      },
      "source": [
        "### Ciclo di Addestramento e Valutazione\n",
        "\n",
        "Questa sezione finale contiene il cuore pulsante del progetto: le funzioni che definiscono il ciclo di addestramento e valutazione del modello. Il codice è strutturato in tre parti principali per garantire chiarezza e modularità.\n",
        "\n",
        "#### Funzione di Addestramento per Epoca (`train_one_epoch`)\n",
        "Questa funzione incapsula tutta la logica necessaria per eseguire una singola epoca di addestramento. Le sue responsabilità includono:\n",
        "-   **Iterazione sui Dati**: Scorre attraverso i batch forniti dal `train_loader`.\n",
        "-   **Passaggio Forward e Calcolo della Loss**: Esegue il passaggio forward del modello per ottenere sia i *logit* sia le *feature*, che vengono poi usati per calcolare la nostra `ContrastativeFocalLoss` ibrida.\n",
        "-   **Mixed Precision Training**: Per accelerare l'addestramento e ridurre l'uso di memoria della GPU, viene utilizzata la precisione mista (`torch.autocast`). Il `GradScaler` gestisce in modo sicuro il calcolo dei gradienti per prevenire problemi di underflow numerico.\n",
        "-   **Backpropagation e Ottimizzazione**: Calcola i gradienti, applica il **Gradient Clipping** (con `max_norm=1.0`) per prevenire gradienti esplosivi e stabilizzare l'addestramento, e infine aggiorna i pesi del modello.\n",
        "-   **Calcolo delle Metriche**: Restituisce la loss media e l'accuracy per l'epoca di addestramento.\n",
        "\n",
        "#### Funzione di Valutazione (`testing`)\n",
        "Questa funzione è dedicata a valutare le performance del modello sul set di test (o validazione) al termine di ogni epoca. È decorata con `@torch.no_grad()` per disattivare il calcolo dei gradienti, rendendo l'inferenza più veloce e sicura.\n",
        "-   **Modalità di Valutazione**: Imposta il modello in `model.eval()` per disattivare strati come Dropout e BatchNorm.\n",
        "-   **Calcolo di Metriche Complete**: Oltre alla loss e all'accuracy, calcola un set completo di metriche di classificazione utilizzando `scikit-learn`:\n",
        "    -   **Precision, Recall, F1-Score**: Per una valutazione approfondita dell'equilibrio del classificatore.\n",
        "    -   **AUC (Area Under the Curve)**: Per misurare la capacità del modello di distinguere tra le classi.\n",
        "    -   **Matrice di Confusione**: Per visualizzare in dettaglio gli errori di classificazione (veri positivi, falsi negativi, ecc.).\n",
        "-   **Output Strutturato**: Restituisce un dizionario contenente tutte le metriche calcolate e l'oggetto della matrice di confusione.\n",
        "\n",
        "#### Ciclo Principale di Addestramento (`train_model`)\n",
        "Questa è la funzione orchestratrice che esegue l'intero processo di addestramento per un numero specificato di epoche.\n",
        "-   **Inizializzazione**: Prepara il `GradScaler` e l'istanza della classe `EarlyStopping`.\n",
        "-   **Loop sulle Epoche**: Per ogni epoca, esegue in sequenza `train_one_epoch` e `testing`.\n",
        "-   **Aggiornamento dello Scheduler**: Dopo ogni epoca di valutazione, aggiorna il learning rate secondo la strategia del `CosineAnnealingWarmRestarts`.\n",
        "-   **Logging e Monitoraggio**: Stampa un riepilogo dettagliato delle performance di training e test, inclusi F1-score, AUC e il learning rate corrente. Mostra anche la matrice di confusione.\n",
        "-   **Controllo Early Stopping**: Utilizza l'**F1-score** sul set di test come metrica chiave per decidere se l'addestramento deve continuare. Se non ci sono miglioramenti per un numero di epoche pari a `patience`, il ciclo viene interrotto e il modello con le migliori performance viene conservato."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1t3JWvYsKFHr"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader, criterion, optimizer, scaler, device, use_mixed_precision):\n",
        "  model.train()\n",
        "\n",
        "  total_loss = 0.0\n",
        "  correct,total = 0,0\n",
        "\n",
        "  for rgb,depth,label in tqdm(loader,desc=\"Training\",leave=False):\n",
        "    rgb, depth, label = rgb.to(device), depth.to(device), label.to(device)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if use_mixed_precision and scaler is not None:\n",
        "        with torch.autocast(device_type='cuda'):\n",
        "            out, features = model(rgb, depth, return_features=True)\n",
        "            loss = criterion(out, features, label)\n",
        "        scaler.scale(loss).backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        #FIX: Calcola accuracy FUORI dal context autocast\n",
        "        with torch.no_grad():\n",
        "            # Ricalcola forward in float32 per accuracy stabile\n",
        "            out_eval = model(rgb, depth, return_features=False)\n",
        "            preds = out_eval.argmax(1)\n",
        "            correct += (preds == label).sum().item()\n",
        "    else:\n",
        "        out, features = model(rgb, depth, return_features=True)\n",
        "        loss = criterion(out, features, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accuracy calculation\n",
        "        preds = out.argmax(1)\n",
        "        correct += (preds == label).sum().item()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total += label.size(0)\n",
        "\n",
        "  avg_loss = total_loss / len(loader)\n",
        "  accuracy = 100 * correct / total\n",
        "  return avg_loss, accuracy\n",
        "\n",
        "@torch.no_grad()\n",
        "def testing(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct, total = 0, 0\n",
        "    all_preds, all_labels, all_probs = [], [], []\n",
        "\n",
        "    for rgb, depth, label in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
        "        rgb, depth, label = rgb.to(device), depth.to(device), label.to(device)\n",
        "\n",
        "        out = model(rgb, depth, return_features=False)\n",
        "        loss = criterion(out, label)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        probs = F.softmax(out, dim=1)\n",
        "        preds = out.argmax(1)\n",
        "\n",
        "        correct += (preds == label).sum().item()\n",
        "        total += label.size(0)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(label.cpu().numpy())\n",
        "        #FIX: Prendi SOLO la probabilità della classe 1 (fake)\n",
        "        all_probs.extend(probs[:, 1].cpu().numpy())  # Non probs.cpu().numpy()\n",
        "\n",
        "    metrics = {\n",
        "        'loss': total_loss / len(loader),\n",
        "        'accuracy': 100 * correct / total,\n",
        "        'precision': precision_score(all_labels, all_preds, zero_division=0),\n",
        "        'recall': recall_score(all_labels, all_preds, zero_division=0),\n",
        "        'f1': f1_score(all_labels, all_preds, zero_division=0),\n",
        "        'auc': roc_auc_score(all_labels, all_probs) if len(set(all_labels)) > 1 else 0.0,\n",
        "        'predictions': all_preds,\n",
        "        'labels': all_labels\n",
        "    }\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    return metrics, cm\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler,\n",
        "                device, epochs=100, patience=15, use_mixed_precision=True, save_path='best_model.pth'):\n",
        "\n",
        "  scaler = GradScaler() if use_mixed_precision else None\n",
        "  best_loss = float('inf')\n",
        "  early_stopping = EarlyStopping()\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "      print(\"-\" * 40)\n",
        "\n",
        "      train_loss,train_acc = train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, use_mixed_precision)\n",
        "      test_metrics, cm = testing(model, test_loader, criterion, device)\n",
        "\n",
        "      scheduler.step()\n",
        "\n",
        "      # Stampa metriche\n",
        "      print(f\"   Train → Loss: {train_loss:.4f} | Acc: {train_acc:.2f}%\")\n",
        "      print(f\"   Test  → Loss: {test_metrics['loss']:.4f} | Acc: {test_metrics['accuracy']:.2f}%\")\n",
        "      print(f\"   Metrics → P: {test_metrics['precision']:.3f} | R: {test_metrics['recall']:.3f} | F1: {test_metrics['f1']:.3f} | AUC: {test_metrics['auc']:.3f}\")\n",
        "      print(f\"   LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "      print(f\"\\nConfusion matrix: \\n{cm}\\n\")\n",
        "\n",
        "      # Early stopping (usa F1 come metrica principale)\n",
        "      should_stop = early_stopping(\n",
        "          test_metrics['f1'],\n",
        "          model,\n",
        "          optimizer,\n",
        "          epoch,\n",
        "          test_acc=test_metrics['accuracy'],\n",
        "          f1=test_metrics['f1']\n",
        "      )\n",
        "\n",
        "      if not should_stop:\n",
        "          print(f\"No improvement: {early_stopping.counter}/{patience}\")\n",
        "\n",
        "      if should_stop:\n",
        "          print(f\"\\nEarly stopping triggered at epoch {epoch+1}\")\n",
        "          break\n",
        "\n",
        "  print(f\"\\n{'='*60}\")\n",
        "  print(f\"Training completato!\")\n",
        "  print(f\"{'='*60}\\n\")\n",
        "\n",
        "  return early_stopping.best_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6nckJ2YPr2a",
        "outputId": "ff5b8f95-20bf-47ff-b70b-e84bebe29d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 1.0560 | Acc: 51.50%\n",
            "   Test  → Loss: 0.0450 | Acc: 47.43%\n",
            "   Metrics → P: 0.964 | R: 0.317 | F1: 0.477 | AUC: 0.813\n",
            "   LR: 0.000098\n",
            "\n",
            "Confusion matrix: \n",
            "[[389  15]\n",
            " [855 396]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.4765\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 2/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 1.0504 | Acc: 55.11%\n",
            "   Test  → Loss: 0.0394 | Acc: 62.05%\n",
            "   Metrics → P: 0.998 | R: 0.499 | F1: 0.665 | AUC: 0.936\n",
            "   LR: 0.000091\n",
            "\n",
            "Confusion matrix: \n",
            "[[403   1]\n",
            " [627 624]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.6652\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 3/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 1.0449 | Acc: 57.68%\n",
            "   Test  → Loss: 0.0359 | Acc: 68.34%\n",
            "   Metrics → P: 1.000 | R: 0.581 | F1: 0.735 | AUC: 0.953\n",
            "   LR: 0.000080\n",
            "\n",
            "Confusion matrix: \n",
            "[[404   0]\n",
            " [524 727]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.7351\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 4/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 1.0390 | Acc: 63.83%\n",
            "   Test  → Loss: 0.0350 | Acc: 73.35%\n",
            "   Metrics → P: 0.999 | R: 0.648 | F1: 0.786 | AUC: 0.961\n",
            "   LR: 0.000066\n",
            "\n",
            "Confusion matrix: \n",
            "[[403   1]\n",
            " [440 811]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.7862\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 5/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 1.0310 | Acc: 68.56%\n",
            "   Test  → Loss: 0.0315 | Acc: 75.95%\n",
            "   Metrics → P: 0.999 | R: 0.683 | F1: 0.811 | AUC: 0.975\n",
            "   LR: 0.000051\n",
            "\n",
            "Confusion matrix: \n",
            "[[403   1]\n",
            " [397 854]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.8110\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 6/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 1.0248 | Acc: 73.63%\n",
            "   Test  → Loss: 0.0236 | Acc: 83.63%\n",
            "   Metrics → P: 0.999 | R: 0.784 | F1: 0.879 | AUC: 0.987\n",
            "   LR: 0.000035\n",
            "\n",
            "Confusion matrix: \n",
            "[[403   1]\n",
            " [270 981]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.8786\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 7/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 1.0208 | Acc: 77.03%\n",
            "   Test  → Loss: 0.0265 | Acc: 81.15%\n",
            "   Metrics → P: 1.000 | R: 0.751 | F1: 0.858 | AUC: 0.986\n",
            "   LR: 0.000021\n",
            "\n",
            "Confusion matrix: \n",
            "[[404   0]\n",
            " [312 939]]\n",
            "\n",
            "Nessun miglioramento (counter 1/15)\n",
            "No improvement: 1/15\n",
            "\n",
            "Epoch 8/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 1.0155 | Acc: 77.20%\n",
            "   Test  → Loss: 0.0218 | Acc: 85.38%\n",
            "   Metrics → P: 1.000 | R: 0.807 | F1: 0.893 | AUC: 0.990\n",
            "   LR: 0.000010\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 404    0]\n",
            " [ 242 1009]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.8929\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 9/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 1.0142 | Acc: 77.12%\n",
            "   Test  → Loss: 0.0218 | Acc: 84.59%\n",
            "   Metrics → P: 1.000 | R: 0.796 | F1: 0.887 | AUC: 0.993\n",
            "   LR: 0.000003\n",
            "\n",
            "Confusion matrix: \n",
            "[[404   0]\n",
            " [255 996]]\n",
            "\n",
            "Nessun miglioramento (counter 1/15)\n",
            "No improvement: 1/15\n",
            "\n",
            "Epoch 10/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 1.0121 | Acc: 76.66%\n",
            "   Test  → Loss: 0.0203 | Acc: 85.56%\n",
            "   Metrics → P: 0.999 | R: 0.810 | F1: 0.894 | AUC: 0.993\n",
            "   LR: 0.000100\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [ 238 1013]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.8945\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 11/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 1.0050 | Acc: 79.11%\n",
            "   Test  → Loss: 0.0129 | Acc: 90.76%\n",
            "   Metrics → P: 1.000 | R: 0.878 | F1: 0.935 | AUC: 0.999\n",
            "   LR: 0.000099\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 404    0]\n",
            " [ 153 1098]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.9349\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 12/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.9880 | Acc: 83.35%\n",
            "   Test  → Loss: 0.0132 | Acc: 89.97%\n",
            "   Metrics → P: 1.000 | R: 0.867 | F1: 0.929 | AUC: 1.000\n",
            "   LR: 0.000098\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 404    0]\n",
            " [ 166 1085]]\n",
            "\n",
            "Nessun miglioramento (counter 1/15)\n",
            "No improvement: 1/15\n",
            "\n",
            "Epoch 13/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.9754 | Acc: 84.88%\n",
            "   Test  → Loss: 0.0102 | Acc: 92.87%\n",
            "   Metrics → P: 1.000 | R: 0.906 | F1: 0.951 | AUC: 1.000\n",
            "   LR: 0.000095\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 404    0]\n",
            " [ 118 1133]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.9505\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 14/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.9648 | Acc: 87.29%\n",
            "   Test  → Loss: 0.0096 | Acc: 93.60%\n",
            "   Metrics → P: 1.000 | R: 0.915 | F1: 0.956 | AUC: 0.999\n",
            "   LR: 0.000091\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 404    0]\n",
            " [ 106 1145]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.9558\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 15/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.9509 | Acc: 88.54%\n",
            "   Test  → Loss: 0.0061 | Acc: 96.92%\n",
            "   Metrics → P: 1.000 | R: 0.959 | F1: 0.979 | AUC: 1.000\n",
            "   LR: 0.000086\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 404    0]\n",
            " [  51 1200]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.9792\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 16/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.9416 | Acc: 89.62%\n",
            "   Test  → Loss: 0.0070 | Acc: 95.89%\n",
            "   Metrics → P: 1.000 | R: 0.946 | F1: 0.972 | AUC: 1.000\n",
            "   LR: 0.000080\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 404    0]\n",
            " [  68 1183]]\n",
            "\n",
            "Nessun miglioramento (counter 1/15)\n",
            "No improvement: 1/15\n",
            "\n",
            "Epoch 17/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.9318 | Acc: 90.49%\n",
            "   Test  → Loss: 0.0024 | Acc: 99.64%\n",
            "   Metrics → P: 0.999 | R: 0.996 | F1: 0.998 | AUC: 1.000\n",
            "   LR: 0.000073\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   5 1246]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.9976\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 18/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.9208 | Acc: 91.61%\n",
            "   Test  → Loss: 0.0055 | Acc: 97.40%\n",
            "   Metrics → P: 0.999 | R: 0.966 | F1: 0.983 | AUC: 1.000\n",
            "   LR: 0.000066\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [  42 1209]]\n",
            "\n",
            "Nessun miglioramento (counter 1/15)\n",
            "No improvement: 1/15\n",
            "\n",
            "Epoch 19/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.9090 | Acc: 92.65%\n",
            "   Test  → Loss: 0.0022 | Acc: 99.58%\n",
            "   Metrics → P: 0.999 | R: 0.995 | F1: 0.997 | AUC: 1.000\n",
            "   LR: 0.000058\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   6 1245]]\n",
            "\n",
            "Nessun miglioramento (counter 2/15)\n",
            "No improvement: 2/15\n",
            "\n",
            "Epoch 20/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.9036 | Acc: 92.52%\n",
            "   Test  → Loss: 0.0075 | Acc: 96.19%\n",
            "   Metrics → P: 1.000 | R: 0.950 | F1: 0.974 | AUC: 1.000\n",
            "   LR: 0.000051\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 404    0]\n",
            " [  63 1188]]\n",
            "\n",
            "Nessun miglioramento (counter 3/15)\n",
            "No improvement: 3/15\n",
            "\n",
            "Epoch 21/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.9099 | Acc: 92.28%\n",
            "   Test  → Loss: 0.0032 | Acc: 98.49%\n",
            "   Metrics → P: 1.000 | R: 0.980 | F1: 0.990 | AUC: 1.000\n",
            "   LR: 0.000043\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 404    0]\n",
            " [  25 1226]]\n",
            "\n",
            "Nessun miglioramento (counter 4/15)\n",
            "No improvement: 4/15\n",
            "\n",
            "Epoch 22/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.9052 | Acc: 92.36%\n",
            "   Test  → Loss: 0.0026 | Acc: 98.97%\n",
            "   Metrics → P: 0.999 | R: 0.987 | F1: 0.993 | AUC: 1.000\n",
            "   LR: 0.000035\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [  16 1235]]\n",
            "\n",
            "Nessun miglioramento (counter 5/15)\n",
            "No improvement: 5/15\n",
            "\n",
            "Epoch 23/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8930 | Acc: 93.77%\n",
            "   Test  → Loss: 0.0036 | Acc: 98.43%\n",
            "   Metrics → P: 0.999 | R: 0.980 | F1: 0.990 | AUC: 1.000\n",
            "   LR: 0.000028\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [  25 1226]]\n",
            "\n",
            "Nessun miglioramento (counter 6/15)\n",
            "No improvement: 6/15\n",
            "\n",
            "Epoch 24/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8970 | Acc: 93.60%\n",
            "   Test  → Loss: 0.0016 | Acc: 99.52%\n",
            "   Metrics → P: 0.999 | R: 0.994 | F1: 0.997 | AUC: 1.000\n",
            "   LR: 0.000021\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   7 1244]]\n",
            "\n",
            "Nessun miglioramento (counter 7/15)\n",
            "No improvement: 7/15\n",
            "\n",
            "Epoch 25/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8859 | Acc: 94.35%\n",
            "   Test  → Loss: 0.0033 | Acc: 98.13%\n",
            "   Metrics → P: 0.999 | R: 0.976 | F1: 0.987 | AUC: 1.000\n",
            "   LR: 0.000015\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [  30 1221]]\n",
            "\n",
            "Nessun miglioramento (counter 8/15)\n",
            "No improvement: 8/15\n",
            "\n",
            "Epoch 26/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8899 | Acc: 93.85%\n",
            "   Test  → Loss: 0.0019 | Acc: 99.34%\n",
            "   Metrics → P: 0.999 | R: 0.992 | F1: 0.996 | AUC: 1.000\n",
            "   LR: 0.000010\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [  10 1241]]\n",
            "\n",
            "Nessun miglioramento (counter 9/15)\n",
            "No improvement: 9/15\n",
            "\n",
            "Epoch 27/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8892 | Acc: 93.19%\n",
            "   Test  → Loss: 0.0018 | Acc: 99.34%\n",
            "   Metrics → P: 0.999 | R: 0.992 | F1: 0.996 | AUC: 1.000\n",
            "   LR: 0.000006\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [  10 1241]]\n",
            "\n",
            "Nessun miglioramento (counter 10/15)\n",
            "No improvement: 10/15\n",
            "\n",
            "Epoch 28/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8910 | Acc: 94.31%\n",
            "   Test  → Loss: 0.0017 | Acc: 99.27%\n",
            "   Metrics → P: 0.999 | R: 0.991 | F1: 0.995 | AUC: 1.000\n",
            "   LR: 0.000003\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [  11 1240]]\n",
            "\n",
            "Nessun miglioramento (counter 11/15)\n",
            "No improvement: 11/15\n",
            "\n",
            "Epoch 29/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8857 | Acc: 93.85%\n",
            "   Test  → Loss: 0.0012 | Acc: 99.64%\n",
            "   Metrics → P: 0.999 | R: 0.996 | F1: 0.998 | AUC: 1.000\n",
            "   LR: 0.000002\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   5 1246]]\n",
            "\n",
            "Nessun miglioramento (counter 12/15)\n",
            "No improvement: 12/15\n",
            "\n",
            "Epoch 30/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8810 | Acc: 94.27%\n",
            "   Test  → Loss: 0.0013 | Acc: 99.76%\n",
            "   Metrics → P: 0.999 | R: 0.998 | F1: 0.998 | AUC: 1.000\n",
            "   LR: 0.000100\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   3 1248]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.9984\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 31/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.9076 | Acc: 93.36%\n",
            "   Test  → Loss: 0.0014 | Acc: 99.88%\n",
            "   Metrics → P: 1.000 | R: 0.998 | F1: 0.999 | AUC: 1.000\n",
            "   LR: 0.000100\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 404    0]\n",
            " [   2 1249]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.9992\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 32/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8973 | Acc: 94.14%\n",
            "   Test  → Loss: 0.0073 | Acc: 95.71%\n",
            "   Metrics → P: 0.999 | R: 0.944 | F1: 0.971 | AUC: 1.000\n",
            "   LR: 0.000099\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [  70 1181]]\n",
            "\n",
            "Nessun miglioramento (counter 1/15)\n",
            "No improvement: 1/15\n",
            "\n",
            "Epoch 33/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8982 | Acc: 93.73%\n",
            "   Test  → Loss: 0.0007 | Acc: 99.88%\n",
            "   Metrics → P: 0.999 | R: 0.999 | F1: 0.999 | AUC: 1.000\n",
            "   LR: 0.000099\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   1 1250]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.9992\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 34/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8919 | Acc: 94.23%\n",
            "   Test  → Loss: 0.0019 | Acc: 99.46%\n",
            "   Metrics → P: 1.000 | R: 0.993 | F1: 0.996 | AUC: 1.000\n",
            "   LR: 0.000098\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 404    0]\n",
            " [   9 1242]]\n",
            "\n",
            "Nessun miglioramento (counter 1/15)\n",
            "No improvement: 1/15\n",
            "\n",
            "Epoch 35/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8852 | Acc: 95.22%\n",
            "   Test  → Loss: 0.0009 | Acc: 99.70%\n",
            "   Metrics → P: 0.999 | R: 0.997 | F1: 0.998 | AUC: 1.000\n",
            "   LR: 0.000096\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   4 1247]]\n",
            "\n",
            "Nessun miglioramento (counter 2/15)\n",
            "No improvement: 2/15\n",
            "\n",
            "Epoch 36/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8876 | Acc: 94.48%\n",
            "   Test  → Loss: 0.0006 | Acc: 99.94%\n",
            "   Metrics → P: 1.000 | R: 0.999 | F1: 1.000 | AUC: 1.000\n",
            "   LR: 0.000095\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 404    0]\n",
            " [   1 1250]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.9996\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 37/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8829 | Acc: 95.31%\n",
            "   Test  → Loss: 0.0023 | Acc: 99.27%\n",
            "   Metrics → P: 1.000 | R: 0.990 | F1: 0.995 | AUC: 1.000\n",
            "   LR: 0.000093\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 404    0]\n",
            " [  12 1239]]\n",
            "\n",
            "Nessun miglioramento (counter 1/15)\n",
            "No improvement: 1/15\n",
            "\n",
            "Epoch 38/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8785 | Acc: 95.56%\n",
            "   Test  → Loss: 0.0013 | Acc: 99.46%\n",
            "   Metrics → P: 0.999 | R: 0.994 | F1: 0.996 | AUC: 1.000\n",
            "   LR: 0.000091\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   8 1243]]\n",
            "\n",
            "Nessun miglioramento (counter 2/15)\n",
            "No improvement: 2/15\n",
            "\n",
            "Epoch 39/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8808 | Acc: 95.60%\n",
            "   Test  → Loss: 0.0006 | Acc: 99.82%\n",
            "   Metrics → P: 0.999 | R: 0.998 | F1: 0.999 | AUC: 1.000\n",
            "   LR: 0.000088\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   2 1249]]\n",
            "\n",
            "Nessun miglioramento (counter 3/15)\n",
            "No improvement: 3/15\n",
            "\n",
            "Epoch 40/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8807 | Acc: 95.68%\n",
            "   Test  → Loss: 0.0008 | Acc: 99.76%\n",
            "   Metrics → P: 0.999 | R: 0.998 | F1: 0.998 | AUC: 1.000\n",
            "   LR: 0.000086\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   3 1248]]\n",
            "\n",
            "Nessun miglioramento (counter 4/15)\n",
            "No improvement: 4/15\n",
            "\n",
            "Epoch 41/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8738 | Acc: 96.05%\n",
            "   Test  → Loss: 0.0041 | Acc: 97.89%\n",
            "   Metrics → P: 0.999 | R: 0.973 | F1: 0.986 | AUC: 1.000\n",
            "   LR: 0.000083\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [  34 1217]]\n",
            "\n",
            "Nessun miglioramento (counter 5/15)\n",
            "No improvement: 5/15\n",
            "\n",
            "Epoch 42/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8697 | Acc: 96.64%\n",
            "   Test  → Loss: 0.0012 | Acc: 99.52%\n",
            "   Metrics → P: 0.999 | R: 0.994 | F1: 0.997 | AUC: 1.000\n",
            "   LR: 0.000080\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   7 1244]]\n",
            "\n",
            "Nessun miglioramento (counter 6/15)\n",
            "No improvement: 6/15\n",
            "\n",
            "Epoch 43/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8712 | Acc: 96.76%\n",
            "   Test  → Loss: 0.0019 | Acc: 99.34%\n",
            "   Metrics → P: 0.999 | R: 0.992 | F1: 0.996 | AUC: 1.000\n",
            "   LR: 0.000076\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [  10 1241]]\n",
            "\n",
            "Nessun miglioramento (counter 7/15)\n",
            "No improvement: 7/15\n",
            "\n",
            "Epoch 44/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8717 | Acc: 96.43%\n",
            "   Test  → Loss: 0.0003 | Acc: 99.94%\n",
            "   Metrics → P: 0.999 | R: 1.000 | F1: 1.000 | AUC: 1.000\n",
            "   LR: 0.000073\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   0 1251]]\n",
            "\n",
            "Checkpoint salvato! Score: 0.9996\n",
            "No improvement: 0/15\n",
            "\n",
            "Epoch 45/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8726 | Acc: 96.43%\n",
            "   Test  → Loss: 0.0007 | Acc: 99.70%\n",
            "   Metrics → P: 0.999 | R: 0.997 | F1: 0.998 | AUC: 1.000\n",
            "   LR: 0.000069\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   4 1247]]\n",
            "\n",
            "Nessun miglioramento (counter 1/15)\n",
            "No improvement: 1/15\n",
            "\n",
            "Epoch 46/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8739 | Acc: 96.39%\n",
            "   Test  → Loss: 0.0010 | Acc: 99.52%\n",
            "   Metrics → P: 0.999 | R: 0.994 | F1: 0.997 | AUC: 1.000\n",
            "   LR: 0.000066\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   7 1244]]\n",
            "\n",
            "Nessun miglioramento (counter 2/15)\n",
            "No improvement: 2/15\n",
            "\n",
            "Epoch 47/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8641 | Acc: 97.76%\n",
            "   Test  → Loss: 0.0005 | Acc: 99.88%\n",
            "   Metrics → P: 0.999 | R: 0.999 | F1: 0.999 | AUC: 1.000\n",
            "   LR: 0.000062\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   1 1250]]\n",
            "\n",
            "Nessun miglioramento (counter 3/15)\n",
            "No improvement: 3/15\n",
            "\n",
            "Epoch 48/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8678 | Acc: 96.72%\n",
            "   Test  → Loss: 0.0003 | Acc: 99.94%\n",
            "   Metrics → P: 0.999 | R: 1.000 | F1: 1.000 | AUC: 1.000\n",
            "   LR: 0.000058\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   0 1251]]\n",
            "\n",
            "Nessun miglioramento (counter 4/15)\n",
            "No improvement: 4/15\n",
            "\n",
            "Epoch 49/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8727 | Acc: 96.76%\n",
            "   Test  → Loss: 0.0003 | Acc: 99.94%\n",
            "   Metrics → P: 0.999 | R: 1.000 | F1: 1.000 | AUC: 1.000\n",
            "   LR: 0.000054\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   0 1251]]\n",
            "\n",
            "Nessun miglioramento (counter 5/15)\n",
            "No improvement: 5/15\n",
            "\n",
            "Epoch 50/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8670 | Acc: 96.55%\n",
            "   Test  → Loss: 0.0014 | Acc: 99.46%\n",
            "   Metrics → P: 0.999 | R: 0.994 | F1: 0.996 | AUC: 1.000\n",
            "   LR: 0.000051\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   8 1243]]\n",
            "\n",
            "Nessun miglioramento (counter 6/15)\n",
            "No improvement: 6/15\n",
            "\n",
            "Epoch 51/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8643 | Acc: 97.26%\n",
            "   Test  → Loss: 0.0006 | Acc: 99.76%\n",
            "   Metrics → P: 0.999 | R: 0.998 | F1: 0.998 | AUC: 1.000\n",
            "   LR: 0.000047\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   3 1248]]\n",
            "\n",
            "Nessun miglioramento (counter 7/15)\n",
            "No improvement: 7/15\n",
            "\n",
            "Epoch 52/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8607 | Acc: 96.84%\n",
            "   Test  → Loss: 0.0004 | Acc: 99.76%\n",
            "   Metrics → P: 0.999 | R: 0.998 | F1: 0.998 | AUC: 1.000\n",
            "   LR: 0.000043\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   3 1248]]\n",
            "\n",
            "Nessun miglioramento (counter 8/15)\n",
            "No improvement: 8/15\n",
            "\n",
            "Epoch 53/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8684 | Acc: 96.93%\n",
            "   Test  → Loss: 0.0006 | Acc: 99.76%\n",
            "   Metrics → P: 0.999 | R: 0.998 | F1: 0.998 | AUC: 1.000\n",
            "   LR: 0.000039\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   3 1248]]\n",
            "\n",
            "Nessun miglioramento (counter 9/15)\n",
            "No improvement: 9/15\n",
            "\n",
            "Epoch 54/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8625 | Acc: 97.09%\n",
            "   Test  → Loss: 0.0004 | Acc: 99.94%\n",
            "   Metrics → P: 0.999 | R: 1.000 | F1: 1.000 | AUC: 1.000\n",
            "   LR: 0.000035\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   0 1251]]\n",
            "\n",
            "Nessun miglioramento (counter 10/15)\n",
            "No improvement: 10/15\n",
            "\n",
            "Epoch 55/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8614 | Acc: 97.38%\n",
            "   Test  → Loss: 0.0004 | Acc: 99.82%\n",
            "   Metrics → P: 0.999 | R: 0.998 | F1: 0.999 | AUC: 1.000\n",
            "   LR: 0.000032\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   2 1249]]\n",
            "\n",
            "Nessun miglioramento (counter 11/15)\n",
            "No improvement: 11/15\n",
            "\n",
            "Epoch 56/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8585 | Acc: 97.38%\n",
            "   Test  → Loss: 0.0003 | Acc: 99.94%\n",
            "   Metrics → P: 0.999 | R: 1.000 | F1: 1.000 | AUC: 1.000\n",
            "   LR: 0.000028\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   0 1251]]\n",
            "\n",
            "Nessun miglioramento (counter 12/15)\n",
            "No improvement: 12/15\n",
            "\n",
            "Epoch 57/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8567 | Acc: 97.34%\n",
            "   Test  → Loss: 0.0003 | Acc: 99.94%\n",
            "   Metrics → P: 0.999 | R: 1.000 | F1: 1.000 | AUC: 1.000\n",
            "   LR: 0.000025\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   0 1251]]\n",
            "\n",
            "Nessun miglioramento (counter 13/15)\n",
            "No improvement: 13/15\n",
            "\n",
            "Epoch 58/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8633 | Acc: 97.18%\n",
            "   Test  → Loss: 0.0003 | Acc: 99.94%\n",
            "   Metrics → P: 0.999 | R: 1.000 | F1: 1.000 | AUC: 1.000\n",
            "   LR: 0.000021\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   0 1251]]\n",
            "\n",
            "Nessun miglioramento (counter 14/15)\n",
            "No improvement: 14/15\n",
            "\n",
            "Epoch 59/100\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Train → Loss: 0.8568 | Acc: 97.72%\n",
            "   Test  → Loss: 0.0013 | Acc: 99.58%\n",
            "   Metrics → P: 0.999 | R: 0.995 | F1: 0.997 | AUC: 1.000\n",
            "   LR: 0.000018\n",
            "\n",
            "Confusion matrix: \n",
            "[[ 403    1]\n",
            " [   6 1245]]\n",
            "\n",
            "Nessun miglioramento (counter 15/15)\n",
            "\n",
            "Early stopping triggered at epoch 59\n",
            "\n",
            "============================================================\n",
            "Training completato!\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "best_f1 = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    test_loader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    device=device,\n",
        "    epochs=100,\n",
        "    patience=15,\n",
        "    use_mixed_precision=use_mixed_precision,\n",
        "    save_path=\"best_antispoofing_improved.pth\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rieux",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
